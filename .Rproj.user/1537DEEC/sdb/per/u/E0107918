{
    "contents" : "---\ntitle: 'ESTADISTICA III: Evidencia de Aprendizaje Unidad 3'\nauthor: \"Carlos Antonio Lara Verduzco ,\\n Néstor Humberto Palafox Elizalde ,\\n Lizeth\n  Vargas Vera, \\n Armando Jiménez Martínez ,\\n Claudio Ramón Rodríguez Mondragón ,\\n\n  Aurelio Plancarte Coria                \"\ndate: \"VIERNES, Septiembre 04, 2015\"\noutput: pdf_document\n---\n\nPara la evidencia de aprendizaje, se introdujeron los datos proporcionados en el archivo en R y se graficaron utilizando el software para obtener sus correlogramas :\n\n```{r}\n\nsetwd(\"~/Estadistica 3\")\nDatos <- read.table(\"datos.txt\", sep=\"\\t\")\nTiempo<- 0:199\nlibrary(\"ggplot2\")\nDat<- data.frame(Tiempo,Datos)\nlibrary(plyr)\nDat<- rename(Dat, c(\"V1\"=\"Datos\"))\n\nbp<- ggplot(data=Dat, aes(x=Tiempo, y=Datos, group=1)) +\n  geom_line(colour=\"grey\", linetype=\"solid\", size=1.5) +\n  geom_point(colour=\"red\", size=3, shape=21, fill=\"white\")\n\nbp + ggtitle(\"DATOS ORIGINALES\") +\n  theme(plot.title = element_text(lineheight=.8, face=\"bold\"))\n\n\n```\n\nLos correlogramas correspondientes a $ACF$  y $PACF$  a los datos son los siguientes:\n\n```{r, echo=FALSE}\nacf(Dat[,2], na.action = na.pass,  main = \"AFC Autocorrelación\")\npacf(Dat[,2], na.action = na.pass,  main = \"PAFC Autocorrelación Parcial\")\n```\n\nDe los correlogramas si nos guiarnos por $PACF$ y tratamos de proponer modelos tipo $AR(p)$, pero los datos en principio no presentaron estacionariedad alguna y por tanto requerimos  transformarlos. Como sugerencia de la Evidencia, estabilizamos la varianza con una transformación logarítmica y nuestro resultado es el siguiente:\n\n```{r}\nDatosLog<- log(Dat[,2])\nts.plot(DatosLog,col=8,main=\"Ajuste logarítmico\", xlab = \"Tiempo\")\n\n\n```\n\nPara tomar una decision, se realizo una transformación por datos diferenciados primero a los datos reales y luego a los datos de la transformación logarítmica para ver cuáles son más estacionarios, tal que:\n\n```{r}\nDatosD1<-diff(Dat[,2])\nts.plot(DatosD1,col=8,main=\"Datos originales diferenciados\", xlab = \"Tiempo\" )\n# se calcula la primera diferencia para los datos con transformación logarítmica:\nDatosD2<-diff(DatosLog)\nts.plot(DatosD2,col=8,main=\"Datos Log diferenciados\")\n\n\n\n```\n\nComo se puede observar  las transformaciones fueron utiles para primero estabilizar la varianza y luego la media, mediante ajustes logarítmico y de datos diferenciados (empleando primera diferencia). Utilizando los datos transformados, calculamos sus correlogramas:\n\n\n\n```{r}\n\nacf(DatosD2,main=\"Autocorrelación para Datos Log Diferenciados\",ylim=c(-1,1),ci.col=\"grey \",ylab=\"ACF\")\npacf(DatosD2,main=\"Autocorrelación parcial para Datos Log Diferenciados\",ci.col=\"grey\",ylab=\"PACF\")\n\n\n```\n\nDe los correlogramas, la $ACF$ considera como posible candidato un modelo $MA(5)$ ,mientras que la $PACF$ nos sugiere un modelo $AR(1)$. Con lo anterior, se procede a hacer la estimación con el paquete R utilizando la función $arima()$ que estima los parámetros del modelo y varianza del ruido blanco utilizando máxima verosimilitud. Para esto, tenemos que los datos ya han sido transformados por lo que ahora consideramos los datos transformados centrados respecto a su media, es decir:\n\n```{r}\n\nDatosCen<-DatosD2-mean(DatosD2)\nts.plot(DatosCen,main=\"Datos Transformados y centrado\",xlab = \"Tiempo\",col=8)\n\n\n```\n\nSe utilizo la función $arima()$ para la estimación del modelo $MA(5)$ por lo que se obtuvo lo siguiente:\n\n```{r}\n\nma5fift<-arima(DatosCen,c(0,0,5))\nma5fift\n\n\n```\n\nEl programa calcula un intercepto o estimador -0.0019, el cual no es significativo aunque se puede ver esto haciendo viendo un intervalo de confianza del 95% mediante:\n\n$$I=(-0.0019-1.96*0.0216,-0.0019+1.96*0.0216)=(-0.044236,0.040436)$$\n\nComo en el intervalo anterior está contenido el 0, se establece que μ=0 y el modelo para los datos centrados sería:\n\n$$ Y^{'}_{t} = \\epsilon_{t} + 0.7666\\epsilon_{t-2} + 0.4036\\epsilon_{t-3} + 0.3027\\epsilon_{t-4} + 0.1187\\epsilon_{t-5} $$\n\nLuego para el caso del modelo $AR(1)$ utilizando “arima()” se obtiene el siguiente resultado:\n\n\n```{r}\n\n#estimación modelo AR(1):\nar1fift<-arima(DatosCen,c(1,0,0))\nar1fift\n\n\n\n```\n\nPara este caso también se tiene un estimador igual a $-0.0015$, el cual tampoco podría ser significativo pero lo verificamos también mediante el intervalo de confianza calculando:\n\n$I=(-0.0015-1.96*0.0262,-0.0015+1.96*0.0262)=(-0.51502,0.51202)$\n\nPara este caso también se establece que μ=0 y el modelo para los datos centrados sería:\n\n$$Y_{t}^{'}= 0.7290Y_{t-1}^{'}+\\epsilon_{t}$$\n\nLa función $arima()$ a estimado también el coeficiente $AIC$ de manera que utilizando este criterio de selección, vemos que el coeficiente para $MA(5)$ es -334.43 y para $AR(1)$ es de -339.34 por lo que el modelo que mejor representa los datos centrados, podría ser $MA(4)$. Sin embargo, más que decantarnos por algún modelo, trataremos de ver si ambos son válidos o solo uno de ellos. Para esto, se analizan los residuales con el fin de ver si el ruido blanco es gaussiano. Si esto es así, los modelos estimados son válidos pues los suponemos con un ruido blanco de estas características. Tomemos entonces los residuales del modelo $MA(4)$ y su histograma obtenido mediante el paquete R:\n\n```{r}\n\n#residuales del modelo MA(5):\npar(mfrow=c(2,1))\nres1<-ma5fift$residuals\nqqnorm(res1)\nqqline(res1)\nqqline(res1,col=2)\nhist(res1)\n\n```\n\nEl histograma en este caso también aparenta una distribución gaussiana, pero se aprecia que tiene más sesgo que en el caso anterior. De cualquier manera para la hipótesis de normalidad usamos el test de Shapiro-Wilks el cual arroja el resultado:\n\n```{r}\n\nshapiro.test(res1)$p.value\n\n\n```\n\nEste test se maneja con un nivel de tolerancia del 5% y como vemos, el resultado es mayor por lo que no se rechaza la hipótesis de normalidad para los residuales, es decir, siguen una distribución normal. Podemos calcular directamente su varianza y media para comprobar si es estándar:\n\n```{r}\n\nmean(res1)\nsd(res1)\n\n```\n\nDe lo anterior se deduce que los residuales para el caso $AR(1)$ presentan un comportamiento gaussiano con media y varianza muy próximas a 0 y 1 respectivamente. Ahora veamos si los residuales son un ruido blanco; esto mediante la función $tsdiag()$ pero esta vez aplicada al objeto ar1fift. El resultado es el siguiente:\n\n\n```{r}\n\ntsdiag(ma5fift)\n\n```\n\nAquí se verifica que efectivamente los valores de los residuales para el modelo $MA(4)$ no están correlacionados y por lo tanto, en dicho modelo, ε_t es un ruido blanco de media 0 y varianza 1 por lo que el modelo $MA(4)$ estimado es válido para los datos centrados.\nAhora hacemos el mismo procedimiento para el proceso $AR(1)$:\n\n\n```{r}\n\n#residuales del modelo AR(1):\npar(mfrow=c(2,1))\nres2<-ar1fift$residuals\nqqnorm(res2)\nqqline(res2)\nqqline(res2,col=2)\nhist(res2)\n\n```\n\nEl histograma en este caso también aparenta una distribución normal, pero se aprecia que tiene más sesgo que en el caso anterior. De cualquier manera para la hipótesis de normalidad usamos el test de Shapiro-Wilks el cual arroja el resultado:\n\n```{r}\n\nshapiro.test(res2)$p.value\n\n\n```\n\nVemos como para un nivel de confianza del 5%, el valor calculado es mucho mayor; aproximadamente del 92% por lo que no se rechaza la hipótesis de normalidad para los residuales. Si calculamos su media y varianza obtenemos\n\n```{r}\n\nmean(res2)\nsd(res2)\n\n```\n\n\nDe lo anterior se deduce que los residuales para el caso $AR(1)$ presentan un comportamiento gaussiano con media y varianza muy próximas a 0 y 1 respectivamente. Ahora veamos si los residuales son un ruido blanco; esto mediante la función $tsdiag()$ pero esta vez aplicada al objeto ar1fift. El resultado es el siguiente:\n\n\n```{r}\n\ntsdiag(ar1fift)\n\n```\n\nA partir de la ACF, es fácil ver que los residuales no presentan correlación alguna. Con este hecho y con la prueba de normalidad, podemos concluir que para el modelo $AR(1)$ ε_t es un ruido blanco de  $\\mu=0$ y $\\sigma^{2}= 1$ y el modelo en cuestión es válido como ajuste para los datos centrados.\nEntonces, la función $arima()$ que se utilizo en la estimación de los modelos $MA(5)$ y $AR(1)$, ha calculado también el coeficiente $AIC$. Ambos modelos son válidos como hemos comprobado anteriormente, pero si queremos saber cuál es más apropiado o próximo a nuestros datos, este será el de menor coeficiente AIC, por tanto, como para $MA(5)$ es de -334.43 y para $AR(1)$ es de -339.34, el modelo $AR(1)$ es más el adecuado. \nPor último, con los modelos obtenidos, ambos válidos para los datos transformados y centrados, haremos una predicción por cada uno de ellos. Como los datos proporcionados no nos dicen nada sobre lo que representan, la predicción se hará sobre 50 datos adicionales a partir de las 200 observaciones. Esto se hace teniendo instalada la librería $forecast$ en R y para el caso de $MA(5)$ se tiene:\n\n```{r}\n\nPredMA<-predict(ma5fift,n.ahead=50)\nPredMA\n\n```\n\nGráficamente se puede observar que:\n\n```{r}\nlibrary(forecast)\nplot(forecast(ma5fift,50),col=8,main=\"Gráfico de predicción MA(5)\" , xlab = \"tiempo\")\n\n```\n\nPara el caso de AR(1) la predicción es la siguiente:\n\n```{r}\n\nPredMA<-predict(ma5fift,n.ahead=50)\nPredMA\n\n```\n\nGráficamente se puede observar que:\n\n```{r}\n#Predicción de datos con el modelo AR(1)\n\nplot(forecast(ar1fift,50),col=8,main=\"Gráfico de predicción AR(1)\", xlab = \"tiempo\")\n\n\n```\n\n## CONCLUSIONES\n\nLos datos presentados en la Evidencia (200 observaciones), en principio no presentaban estacionariedad, por lo cual se realizó una \"transformación logarítmica\" y  despues \"De primera diferencia\" para volver dichos datos estacionarios y asi sugerir un modelo de Serie de Tiempo. De los correlogramas se estimó como posibles modelos $MA(5)$ y $AR(1)$ confirmados mediante análisis hechos en R. Dicho análisis validó ambos modelos como adecuados para los datos transformados y centrados y además, mediante test AIC, se dedujo que el más apropiado es el $AR(1)$. Los datos presentados son una serie de números, pero no se indica que representen alguna situación en específico, por lo que se ha decidido hacer una predicción consistente en las siguientes 50 observaciones. Dicha predicción se realizó con ambos modelos $MA(5)$ y $AR(1)$ y de la gráfica de dichas predicciones se observa un comportamiento muy similar, esto corrobora la validez de ambos modelos. Por último, del test $AIC$ sabemos que $AR(1)$ es más adecuado, por lo que se concluye que la predicción hecha con este modelo tendrá una mayor precisión.\n",
    "created" : 1441507214016.000,
    "dirty" : true,
    "encoding" : "",
    "folds" : "",
    "hash" : "1590034967",
    "id" : "E0107918",
    "lastKnownWriteTime" : 1868832878,
    "path" : null,
    "project_path" : null,
    "properties" : {
        "tempName" : "Untitled6"
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}